---
layout: default
permalink: /models/regression
---

# Regression
Regression is the study of how to best fit a curve to summarize data. It falls under supervised learning wherein the algorithm is trained with both input features and output labels. It is a set of statistical processes for estimating the relationships between a dependent variable (outcome) and one or more independent variables (predictors, covariates, explanatory variables or features).

The most popular regression form is linear regression, in which one finds a line that most closely fits the data according to some mathematical criterion. One example is the method of ordinary least squares that minimizes the sum of squared differences between the true data and such line. It is also the earliest form of regression, published in 1805 by Legendre and 1809 by Gauss. Both applied the method to determine the orbits of bodies around the Sun from astronomical observations.

Another regression form is polynomial regression, in which a polynomial is fitted to the data. 

Regression in general is mostly used for prediction and forecasting, as well as determining causal relationships between variables.
